---
title: "Linear Regression simple model"
output: html_notebook
---

```{r}
library(ggplot2)
library(tibble)
library(dplyr)
```

```{r}
sim1 <- modelr::sim1
sim1
```

```{r}
ggplot(sim1, aes(x,y))+
  geom_point()
```


#exploratory analysis was the graphing, to determine if it's linear. graphing the lines was model creation. the a1 and a2 were parameters to linear equations.
```{r}
models <- tibble(
  a1 = runif(250,-20,40),
  a2 = runif(250,-5,5)
)

ggplot(sim1,aes(x,y))+
  geom_point()+
  geom_abline(aes(intercept = a1, slope = a2), data = models, alpha = .15)
```

#has input a,data and it takes the position of a1, which is our y-intercept, and continually adds the slope of 1.5. Both of these are given in our a input. data is taking the x input from our actual data. the model1 produces a output based off the value of the x's in the data.
```{r}
model1 <- function(a,data){
  a[1] + data$x *a[2]
  #this is just y= mx+b
}
model1(c(7,1.5), sim1)
#we manually created a model with parameters y-intercept is 7 and 1.5 is the slope. The return uses all the x values from data and plugs them into y=mx +b with our chosen slope and inntercept.
```
#root mean squared deviation
#this takes the model above and finds the difference between the outputs of the actual data and the model, then takes the root mean squared deviation.
```{r}
measure_distance <- function(mod, data){
  diff<- data$y - model1(mod,data)
  sqrt(mean(diff^2))
}
measure_distance(c(7,1.5),sim1)
measure_distance(c(6,1),sim1)

```

#since a1 and a2 are the models slope and intercept, we want it variable, but sim1 is the data we are modeling so we can integrate that data into the function
```{r}
sim1_dist <- function(a1,a2){
  measure_distance(c(a1,a2), sim1)
  #measuring the distance using the randomly generated y-intercept(a1) and slope(a2) to the data (sim1)
}
# i created a new function sim1_dist that's was not a general version of measure_distance. That way I can easily apply the function across all rows in models.
models <- models %>% 
  mutate(dist = purrr::map2_dbl(a1,a2, sim1_dist))
models
# create a new column called dist and we use map2 which is a lapply for tidy, where we apply the measuring the distance across all instances of a1 and a2??
```
#since we associated each model with it's corrosponging root mean squared deviation(how well the model fits), we can select the top 10  of those models
```{r}
ggplot(sim1, aes(x,y))+
  geom_point(size = 2, color = "grey30") +
  geom_abline(
    aes(intercept = a1, slope = a2, color = dist),
    data = filter(models, rank(dist) <= 10)# selecting the top 10"rank"
  )
```
#now we are just ploting all slope and intercepts combinationns from a1,a2.
```{r}
ggplot(models, aes(a1,a2))+ #layer 1 plots all points
  geom_point(data = filter(models,rank(dist) <= 10), size = 4, color = "red")+ #layer 2 red circles the top 10
  geom_point(aes(color = -dist))#layer3 colors all points based on min deviation
```
#systematically creates a grid of combinitions of y-intercepts and slopes.
```{r}
# does all combinations of a1 and a2 values.
grid <- expand.grid(
  a1 = seq(-5,20, length = 25),
  a2 = seq(1,3, length = 25)
) %>% 
  mutate(dist = purrr::map2_dbl(a1,a2, sim1_dist))
grid %>%
  ggplot(aes(a1,a2))+
  geom_point(data = filter(grid,rank(dist) <= 10), size = 4, color = "red")+
  geom_point(aes(color = -dist))
# this is acting as a zoomed in version of the values
```
```{r}
ggplot(sim1, aes(x,y)) +
  geom_point(size = 2, color = "grey") +
  geom_abline(
    aes(intercept = a1, slope = a2, color = -dist),
    data = filter(grid,rank(dist) <=10)
  )
```

```{r}
best <- optim(c(0,0), measure_distance, data = sim1)
best
```
```{r}
ggplot(sim1, aes(x,y)) +
  geom_point(size = 2, color = "gray")+
  geom_abline(intercept = best$par[1], slope = best$par[2])
```

base R algorthems
```{r}
sim1_mod <- lm(y ~ x, data = sim1)
sim1_mod
broom::tidy(sim1)
```


#prediction
train? split
```{r}
library(rsample)
data_split <- initial_split(sim1)
data_train <- training(data_split)
data_test <- testing(data_split)
```

model fitting
```{r}
model <- lm(y ~x, data = data_train)
model
```

```{r}
prediction <- predict(model, data_test)
prediction
data_test <- data_test %>% 
  mutate(pred = predition)

ggplot(data_test)+
  geom_line(aes(x,pred), color = "red")+
  geom_point(aes(x,y), size = 5, color = "green", alpha = .5)+
  geom_point(data = sim1, aes(x,y))
```


```{r}
yardstick::metrics(data_test,y,pred)
```



